{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings\n",
    "from typing import List\n",
    "from flair.visual.training_curves import Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings, FlairEmbeddings\n",
    "\n",
    "# initialize embeddings. This takes time to load.\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "    # GloVe embeddings for arabic\n",
    "#     WordEmbeddings('ar'),\n",
    "    FlairEmbeddings('/home/jupyter/language_model/wiki-forward/best-lm.pt'), \n",
    "    FlairEmbeddings('/home/jupyter/language_model/wiki-backward/best-lm.pt')\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-15 16:39:41,700 Reading data from /home/jupyter/data_ner\n",
      "2019-04-15 16:39:41,701 Train: /home/jupyter/data_ner/train.txt\n",
      "2019-04-15 16:39:41,703 Dev: /home/jupyter/data_ner/dev.txt\n",
      "2019-04-15 16:39:41,704 Test: None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. get the corpus\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "data_folder = '/home/jupyter/data_ner/'\n",
    "corpus: TaggedCorpus = NLPTaskDataFetcher.load_column_corpus(data_folder, columns, \n",
    "  train_file='train.txt', \n",
    "  dev_file='dev.txt')\n",
    "\n",
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ner'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "\n",
    "\n",
    "# initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# have a relatively small hidden_size\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=64,\n",
    "                                        dropout = 0.2,\n",
    "                                        rnn_layers = 2,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)# initialize trainer\n",
    "# 6. Initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.training_utils import EvaluationMetric\n",
    "\n",
    "from flair.optim import AdamW\n",
    "# optimizer = optimizer(momentum=0.9, dampening=0.9)\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus, optimizer=AdamW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-15 16:39:53,050 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:39:53,052 Evaluation method: MICRO_F1_SCORE\n",
      "2019-04-15 16:39:53,053 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:39:53,481 epoch 1 - iter 0/38 - loss 61.07507324\n",
      "2019-04-15 16:39:55,211 epoch 1 - iter 3/38 - loss 88.63649559\n",
      "2019-04-15 16:39:56,560 epoch 1 - iter 6/38 - loss 60.63908168\n",
      "2019-04-15 16:39:57,967 epoch 1 - iter 9/38 - loss 47.55303011\n",
      "2019-04-15 16:39:59,860 epoch 1 - iter 12/38 - loss 42.99303194\n",
      "2019-04-15 16:40:01,305 epoch 1 - iter 15/38 - loss 38.34075266\n",
      "2019-04-15 16:40:02,937 epoch 1 - iter 18/38 - loss 35.11664305\n",
      "2019-04-15 16:40:04,502 epoch 1 - iter 21/38 - loss 32.64207628\n",
      "2019-04-15 16:40:06,250 epoch 1 - iter 24/38 - loss 30.87922886\n",
      "2019-04-15 16:40:08,534 epoch 1 - iter 27/38 - loss 29.40119161\n",
      "2019-04-15 16:40:10,306 epoch 1 - iter 30/38 - loss 28.12959286\n",
      "2019-04-15 16:40:12,145 epoch 1 - iter 33/38 - loss 27.03586225\n",
      "2019-04-15 16:40:13,780 epoch 1 - iter 36/38 - loss 26.08285321\n",
      "2019-04-15 16:40:14,095 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:40:14,096 EPOCH 1 done: loss 25.9848 - lr 0.1000 - bad epochs 0\n",
      "2019-04-15 16:40:19,049 DEV  : loss 14.33186436 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:40:21,509 TEST : loss 14.26126575 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:40:21,548 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:40:21,864 epoch 2 - iter 0/38 - loss 14.57751465\n",
      "2019-04-15 16:40:22,954 epoch 2 - iter 3/38 - loss 17.53937554\n",
      "2019-04-15 16:40:24,400 epoch 2 - iter 6/38 - loss 18.16400269\n",
      "2019-04-15 16:40:25,296 epoch 2 - iter 9/38 - loss 16.94820662\n",
      "2019-04-15 16:40:26,095 epoch 2 - iter 12/38 - loss 15.83827033\n",
      "2019-04-15 16:40:27,045 epoch 2 - iter 15/38 - loss 16.04841697\n",
      "2019-04-15 16:40:28,295 epoch 2 - iter 18/38 - loss 17.34059816\n",
      "2019-04-15 16:40:29,321 epoch 2 - iter 21/38 - loss 17.11027471\n",
      "2019-04-15 16:40:30,267 epoch 2 - iter 24/38 - loss 16.98221653\n",
      "2019-04-15 16:40:31,405 epoch 2 - iter 27/38 - loss 16.78885112\n",
      "2019-04-15 16:40:32,232 epoch 2 - iter 30/38 - loss 16.49865055\n",
      "2019-04-15 16:40:33,446 epoch 2 - iter 33/38 - loss 16.54002745\n",
      "2019-04-15 16:40:34,698 epoch 2 - iter 36/38 - loss 16.68882380\n",
      "2019-04-15 16:40:34,951 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:40:34,952 EPOCH 2 done: loss 16.6652 - lr 0.1000 - bad epochs 0\n",
      "2019-04-15 16:40:38,226 DEV  : loss 15.42107391 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:40:39,745 TEST : loss 15.31719875 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:40:39,784 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:40:40,237 epoch 3 - iter 0/38 - loss 30.27135849\n",
      "2019-04-15 16:40:41,267 epoch 3 - iter 3/38 - loss 20.66517282\n",
      "2019-04-15 16:40:42,321 epoch 3 - iter 6/38 - loss 18.36196913\n",
      "2019-04-15 16:40:43,319 epoch 3 - iter 9/38 - loss 16.72865381\n",
      "2019-04-15 16:40:44,502 epoch 3 - iter 12/38 - loss 18.44904364\n",
      "2019-04-15 16:40:45,439 epoch 3 - iter 15/38 - loss 17.87580776\n",
      "2019-04-15 16:40:46,263 epoch 3 - iter 18/38 - loss 17.52474383\n",
      "2019-04-15 16:40:47,332 epoch 3 - iter 21/38 - loss 17.08831718\n",
      "2019-04-15 16:40:48,204 epoch 3 - iter 24/38 - loss 17.14530842\n",
      "2019-04-15 16:40:49,556 epoch 3 - iter 27/38 - loss 17.07142820\n",
      "2019-04-15 16:40:50,490 epoch 3 - iter 30/38 - loss 17.14632920\n",
      "2019-04-15 16:40:51,451 epoch 3 - iter 33/38 - loss 16.89135333\n",
      "2019-04-15 16:40:52,339 epoch 3 - iter 36/38 - loss 16.93837872\n",
      "2019-04-15 16:40:52,544 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:40:52,545 EPOCH 3 done: loss 16.9137 - lr 0.1000 - bad epochs 0\n",
      "2019-04-15 16:40:55,714 DEV  : loss 15.33301353 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:40:57,279 TEST : loss 15.07643414 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:40:57,281 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:40:57,554 epoch 4 - iter 0/38 - loss 17.58965874\n",
      "2019-04-15 16:40:58,812 epoch 4 - iter 3/38 - loss 21.28462076\n",
      "2019-04-15 16:41:00,081 epoch 4 - iter 6/38 - loss 19.68700722\n",
      "2019-04-15 16:41:00,858 epoch 4 - iter 9/38 - loss 18.70919504\n",
      "2019-04-15 16:41:01,901 epoch 4 - iter 12/38 - loss 18.33572718\n",
      "2019-04-15 16:41:03,277 epoch 4 - iter 15/38 - loss 17.62850004\n",
      "2019-04-15 16:41:04,458 epoch 4 - iter 18/38 - loss 17.74037135\n",
      "2019-04-15 16:41:05,520 epoch 4 - iter 21/38 - loss 17.31070185\n",
      "2019-04-15 16:41:06,523 epoch 4 - iter 24/38 - loss 17.60015270\n",
      "2019-04-15 16:41:07,603 epoch 4 - iter 27/38 - loss 17.68838423\n",
      "2019-04-15 16:41:08,549 epoch 4 - iter 30/38 - loss 17.47039167\n",
      "2019-04-15 16:41:09,563 epoch 4 - iter 33/38 - loss 17.49499450\n",
      "2019-04-15 16:41:10,396 epoch 4 - iter 36/38 - loss 17.27272480\n",
      "2019-04-15 16:41:10,744 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:41:10,746 EPOCH 4 done: loss 17.2647 - lr 0.1000 - bad epochs 1\n",
      "2019-04-15 16:41:13,929 DEV  : loss 16.06993675 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:41:15,617 TEST : loss 15.45708275 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:41:15,619 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:41:15,985 epoch 5 - iter 0/38 - loss 14.62337112\n",
      "2019-04-15 16:41:16,857 epoch 5 - iter 3/38 - loss 15.71435857\n",
      "2019-04-15 16:41:17,883 epoch 5 - iter 6/38 - loss 16.93375601\n",
      "2019-04-15 16:41:18,847 epoch 5 - iter 9/38 - loss 16.39775200\n",
      "2019-04-15 16:41:19,721 epoch 5 - iter 12/38 - loss 16.68587200\n",
      "2019-04-15 16:41:20,877 epoch 5 - iter 15/38 - loss 17.62566304\n",
      "2019-04-15 16:41:21,915 epoch 5 - iter 18/38 - loss 17.66355434\n",
      "2019-04-15 16:41:22,965 epoch 5 - iter 21/38 - loss 17.56927421\n",
      "2019-04-15 16:41:24,377 epoch 5 - iter 24/38 - loss 17.73414879\n",
      "2019-04-15 16:41:25,428 epoch 5 - iter 27/38 - loss 17.26519632\n",
      "2019-04-15 16:41:26,356 epoch 5 - iter 30/38 - loss 17.24245290\n",
      "2019-04-15 16:41:27,427 epoch 5 - iter 33/38 - loss 17.26297822\n",
      "2019-04-15 16:41:28,370 epoch 5 - iter 36/38 - loss 17.08374070\n",
      "2019-04-15 16:41:28,513 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:41:28,514 EPOCH 5 done: loss 17.0244 - lr 0.1000 - bad epochs 2\n",
      "2019-04-15 16:41:31,694 DEV  : loss 16.44678879 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:41:33,228 TEST : loss 15.67461395 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:41:33,230 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:41:33,589 epoch 6 - iter 0/38 - loss 16.69931221\n",
      "2019-04-15 16:41:34,808 epoch 6 - iter 3/38 - loss 16.94295216\n",
      "2019-04-15 16:41:35,720 epoch 6 - iter 6/38 - loss 16.54195241\n",
      "2019-04-15 16:41:36,937 epoch 6 - iter 9/38 - loss 16.94874916\n",
      "2019-04-15 16:41:38,137 epoch 6 - iter 12/38 - loss 18.37738382\n",
      "2019-04-15 16:41:39,057 epoch 6 - iter 15/38 - loss 17.33228654\n",
      "2019-04-15 16:41:40,160 epoch 6 - iter 18/38 - loss 17.94266374\n",
      "2019-04-15 16:41:41,315 epoch 6 - iter 21/38 - loss 17.61131594\n",
      "2019-04-15 16:41:42,238 epoch 6 - iter 24/38 - loss 17.48174114\n",
      "2019-04-15 16:41:43,600 epoch 6 - iter 27/38 - loss 17.45514750\n",
      "2019-04-15 16:41:44,552 epoch 6 - iter 30/38 - loss 17.49464300\n",
      "2019-04-15 16:41:45,371 epoch 6 - iter 33/38 - loss 17.30667361\n",
      "2019-04-15 16:41:46,134 epoch 6 - iter 36/38 - loss 17.19084152\n",
      "2019-04-15 16:41:46,303 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:41:46,305 EPOCH 6 done: loss 17.1532 - lr 0.1000 - bad epochs 3\n",
      "2019-04-15 16:41:49,504 DEV  : loss 14.67813492 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:41:51,073 TEST : loss 14.28256989 - f-score 0.0000 - acc 0.0000\n",
      "Epoch     5: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-04-15 16:41:51,075 Epoch 5: reducing weight decay factor of group 0 to 5.0000e-02.\n",
      "2019-04-15 16:41:51,076 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:41:51,402 epoch 7 - iter 0/38 - loss 14.67314911\n",
      "2019-04-15 16:41:52,431 epoch 7 - iter 3/38 - loss 15.42669010\n",
      "2019-04-15 16:41:53,600 epoch 7 - iter 6/38 - loss 18.93316133\n",
      "2019-04-15 16:41:54,558 epoch 7 - iter 9/38 - loss 17.49377089\n",
      "2019-04-15 16:41:55,625 epoch 7 - iter 12/38 - loss 16.86357865\n",
      "2019-04-15 16:41:56,750 epoch 7 - iter 15/38 - loss 16.84354818\n",
      "2019-04-15 16:41:57,845 epoch 7 - iter 18/38 - loss 16.61749007\n",
      "2019-04-15 16:41:58,692 epoch 7 - iter 21/38 - loss 16.36386221\n",
      "2019-04-15 16:41:59,587 epoch 7 - iter 24/38 - loss 15.99548618\n",
      "2019-04-15 16:42:00,551 epoch 7 - iter 27/38 - loss 15.97826253\n",
      "2019-04-15 16:42:02,170 epoch 7 - iter 30/38 - loss 16.21666527\n",
      "2019-04-15 16:42:03,185 epoch 7 - iter 33/38 - loss 16.20486209\n",
      "2019-04-15 16:42:04,280 epoch 7 - iter 36/38 - loss 16.39791994\n",
      "2019-04-15 16:42:04,435 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:42:04,437 EPOCH 7 done: loss 16.3373 - lr 0.0500 - bad epochs 0\n",
      "2019-04-15 16:42:07,655 DEV  : loss 15.21130848 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:42:09,205 TEST : loss 15.03106213 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:42:09,245 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:42:09,547 epoch 8 - iter 0/38 - loss 13.98000431\n",
      "2019-04-15 16:42:10,765 epoch 8 - iter 3/38 - loss 20.93743682\n",
      "2019-04-15 16:42:11,826 epoch 8 - iter 6/38 - loss 17.68663311\n",
      "2019-04-15 16:42:13,202 epoch 8 - iter 9/38 - loss 18.44744768\n",
      "2019-04-15 16:42:14,129 epoch 8 - iter 12/38 - loss 17.92798791\n",
      "2019-04-15 16:42:15,083 epoch 8 - iter 15/38 - loss 17.29915667\n",
      "2019-04-15 16:42:16,021 epoch 8 - iter 18/38 - loss 16.84970324\n",
      "2019-04-15 16:42:16,895 epoch 8 - iter 21/38 - loss 16.59639671\n",
      "2019-04-15 16:42:18,053 epoch 8 - iter 24/38 - loss 16.51166363\n",
      "2019-04-15 16:42:19,124 epoch 8 - iter 27/38 - loss 16.55001235\n",
      "2019-04-15 16:42:20,261 epoch 8 - iter 30/38 - loss 16.76074653\n",
      "2019-04-15 16:42:21,306 epoch 8 - iter 33/38 - loss 16.83320009\n",
      "2019-04-15 16:42:22,228 epoch 8 - iter 36/38 - loss 16.80910345\n",
      "2019-04-15 16:42:22,430 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:42:22,431 EPOCH 8 done: loss 16.7583 - lr 0.0500 - bad epochs 0\n",
      "2019-04-15 16:42:25,632 DEV  : loss 15.73341274 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:42:27,197 TEST : loss 15.62658501 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:42:27,199 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:42:27,464 epoch 9 - iter 0/38 - loss 9.17157364\n",
      "2019-04-15 16:42:28,461 epoch 9 - iter 3/38 - loss 17.25100040\n",
      "2019-04-15 16:42:29,752 epoch 9 - iter 6/38 - loss 20.37886184\n",
      "2019-04-15 16:42:30,746 epoch 9 - iter 9/38 - loss 19.36098051\n",
      "2019-04-15 16:42:32,369 epoch 9 - iter 12/38 - loss 19.71516939\n",
      "2019-04-15 16:42:33,361 epoch 9 - iter 15/38 - loss 18.74137348\n",
      "2019-04-15 16:42:34,375 epoch 9 - iter 18/38 - loss 18.51103286\n",
      "2019-04-15 16:42:35,542 epoch 9 - iter 21/38 - loss 18.10934973\n",
      "2019-04-15 16:42:36,586 epoch 9 - iter 24/38 - loss 17.68550602\n",
      "2019-04-15 16:42:37,345 epoch 9 - iter 27/38 - loss 17.38887807\n",
      "2019-04-15 16:42:38,223 epoch 9 - iter 30/38 - loss 17.25837123\n",
      "2019-04-15 16:42:39,192 epoch 9 - iter 33/38 - loss 17.23372120\n",
      "2019-04-15 16:42:39,987 epoch 9 - iter 36/38 - loss 17.00730999\n",
      "2019-04-15 16:42:40,266 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:42:40,268 EPOCH 9 done: loss 17.0931 - lr 0.0500 - bad epochs 1\n",
      "2019-04-15 16:42:43,412 DEV  : loss 15.44373703 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:42:44,960 TEST : loss 15.55963326 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:42:44,962 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:42:45,332 epoch 10 - iter 0/38 - loss 19.49771500\n",
      "2019-04-15 16:42:46,146 epoch 10 - iter 3/38 - loss 14.88946271\n",
      "2019-04-15 16:42:47,607 epoch 10 - iter 6/38 - loss 19.28918934\n",
      "2019-04-15 16:42:48,521 epoch 10 - iter 9/38 - loss 18.56117630\n",
      "2019-04-15 16:42:49,817 epoch 10 - iter 12/38 - loss 18.51106071\n",
      "2019-04-15 16:42:50,855 epoch 10 - iter 15/38 - loss 18.40557480\n",
      "2019-04-15 16:42:51,864 epoch 10 - iter 18/38 - loss 17.96850852\n",
      "2019-04-15 16:42:52,686 epoch 10 - iter 21/38 - loss 17.51575665\n",
      "2019-04-15 16:42:53,622 epoch 10 - iter 24/38 - loss 17.37675205\n",
      "2019-04-15 16:42:54,575 epoch 10 - iter 27/38 - loss 16.98468501\n",
      "2019-04-15 16:42:55,637 epoch 10 - iter 30/38 - loss 16.88927324\n",
      "2019-04-15 16:42:56,653 epoch 10 - iter 33/38 - loss 16.84582940\n",
      "2019-04-15 16:42:57,628 epoch 10 - iter 36/38 - loss 16.75334113\n",
      "2019-04-15 16:42:57,885 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:42:57,886 EPOCH 10 done: loss 16.8083 - lr 0.0500 - bad epochs 2\n",
      "2019-04-15 16:43:01,033 DEV  : loss 16.69870186 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:43:02,607 TEST : loss 16.21166992 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:43:02,609 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:43:02,955 epoch 11 - iter 0/38 - loss 17.07254410\n",
      "2019-04-15 16:43:03,861 epoch 11 - iter 3/38 - loss 14.60003400\n",
      "2019-04-15 16:43:04,861 epoch 11 - iter 6/38 - loss 15.04913684\n",
      "2019-04-15 16:43:05,876 epoch 11 - iter 9/38 - loss 15.97877073\n",
      "2019-04-15 16:43:06,705 epoch 11 - iter 12/38 - loss 16.09437150\n",
      "2019-04-15 16:43:07,819 epoch 11 - iter 15/38 - loss 16.46229082\n",
      "2019-04-15 16:43:09,207 epoch 11 - iter 18/38 - loss 16.46998320\n",
      "2019-04-15 16:43:10,163 epoch 11 - iter 21/38 - loss 16.65144361\n",
      "2019-04-15 16:43:11,127 epoch 11 - iter 24/38 - loss 16.63402905\n",
      "2019-04-15 16:43:12,047 epoch 11 - iter 27/38 - loss 16.59630132\n",
      "2019-04-15 16:43:13,144 epoch 11 - iter 30/38 - loss 16.52664748\n",
      "2019-04-15 16:43:14,588 epoch 11 - iter 33/38 - loss 17.00979449\n",
      "2019-04-15 16:43:15,599 epoch 11 - iter 36/38 - loss 17.24297165\n",
      "2019-04-15 16:43:15,763 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:43:15,767 EPOCH 11 done: loss 17.1810 - lr 0.0500 - bad epochs 3\n",
      "2019-04-15 16:43:18,968 DEV  : loss 15.37102318 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:43:20,545 TEST : loss 15.39406300 - f-score 0.0000 - acc 0.0000\n",
      "Epoch    10: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2019-04-15 16:43:20,547 Epoch 10: reducing weight decay factor of group 0 to 2.5000e-02.\n",
      "2019-04-15 16:43:20,548 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:43:20,899 epoch 12 - iter 0/38 - loss 16.10577774\n",
      "2019-04-15 16:43:21,917 epoch 12 - iter 3/38 - loss 18.15895748\n",
      "2019-04-15 16:43:22,906 epoch 12 - iter 6/38 - loss 17.38427748\n",
      "2019-04-15 16:43:24,124 epoch 12 - iter 9/38 - loss 19.15375547\n",
      "2019-04-15 16:43:25,124 epoch 12 - iter 12/38 - loss 18.28985324\n",
      "2019-04-15 16:43:26,279 epoch 12 - iter 15/38 - loss 17.69881314\n",
      "2019-04-15 16:43:27,291 epoch 12 - iter 18/38 - loss 17.00345863\n",
      "2019-04-15 16:43:28,193 epoch 12 - iter 21/38 - loss 16.85052018\n",
      "2019-04-15 16:43:29,200 epoch 12 - iter 24/38 - loss 16.65701073\n",
      "2019-04-15 16:43:30,075 epoch 12 - iter 27/38 - loss 16.68442556\n",
      "2019-04-15 16:43:31,024 epoch 12 - iter 30/38 - loss 16.50409877\n",
      "2019-04-15 16:43:32,361 epoch 12 - iter 33/38 - loss 16.45922770\n",
      "2019-04-15 16:43:33,456 epoch 12 - iter 36/38 - loss 16.47467013\n",
      "2019-04-15 16:43:33,618 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:43:33,620 EPOCH 12 done: loss 16.4379 - lr 0.0250 - bad epochs 0\n",
      "2019-04-15 16:43:36,780 DEV  : loss 14.78341007 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:43:38,373 TEST : loss 14.78460026 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:43:38,375 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:43:38,867 epoch 13 - iter 0/38 - loss 13.51405525\n",
      "2019-04-15 16:43:39,903 epoch 13 - iter 3/38 - loss 13.55133891\n",
      "2019-04-15 16:43:41,026 epoch 13 - iter 6/38 - loss 16.54599612\n",
      "2019-04-15 16:43:41,839 epoch 13 - iter 9/38 - loss 15.37380981\n",
      "2019-04-15 16:43:42,934 epoch 13 - iter 12/38 - loss 15.15020158\n",
      "2019-04-15 16:43:44,089 epoch 13 - iter 15/38 - loss 15.55091685\n",
      "2019-04-15 16:43:45,062 epoch 13 - iter 18/38 - loss 15.26215081\n",
      "2019-04-15 16:43:46,010 epoch 13 - iter 21/38 - loss 15.24236896\n",
      "2019-04-15 16:43:46,983 epoch 13 - iter 24/38 - loss 15.56098858\n",
      "2019-04-15 16:43:48,249 epoch 13 - iter 27/38 - loss 16.16391758\n",
      "2019-04-15 16:43:49,158 epoch 13 - iter 30/38 - loss 16.09725629\n",
      "2019-04-15 16:43:50,082 epoch 13 - iter 33/38 - loss 15.98559183\n",
      "2019-04-15 16:43:51,507 epoch 13 - iter 36/38 - loss 15.93732790\n",
      "2019-04-15 16:43:51,698 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:43:51,699 EPOCH 13 done: loss 15.9313 - lr 0.0250 - bad epochs 1\n",
      "2019-04-15 16:43:54,873 DEV  : loss 14.92414474 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:43:56,377 TEST : loss 15.02613163 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:43:56,419 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:43:56,656 epoch 14 - iter 0/38 - loss 15.34270382\n",
      "2019-04-15 16:43:57,749 epoch 14 - iter 3/38 - loss 14.66197371\n",
      "2019-04-15 16:43:58,815 epoch 14 - iter 6/38 - loss 14.75256062\n",
      "2019-04-15 16:44:00,027 epoch 14 - iter 9/38 - loss 16.84686022\n",
      "2019-04-15 16:44:01,068 epoch 14 - iter 12/38 - loss 16.25432073\n",
      "2019-04-15 16:44:01,955 epoch 14 - iter 15/38 - loss 16.14656544\n",
      "2019-04-15 16:44:02,889 epoch 14 - iter 18/38 - loss 15.90429186\n",
      "2019-04-15 16:44:03,776 epoch 14 - iter 21/38 - loss 15.50255741\n",
      "2019-04-15 16:44:04,617 epoch 14 - iter 24/38 - loss 15.39089378\n",
      "2019-04-15 16:44:05,693 epoch 14 - iter 27/38 - loss 15.70561440\n",
      "2019-04-15 16:44:07,058 epoch 14 - iter 30/38 - loss 15.83576230\n",
      "2019-04-15 16:44:08,084 epoch 14 - iter 33/38 - loss 15.59953471\n",
      "2019-04-15 16:44:09,245 epoch 14 - iter 36/38 - loss 15.68341162\n",
      "2019-04-15 16:44:09,384 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:44:09,385 EPOCH 14 done: loss 15.6353 - lr 0.0250 - bad epochs 0\n",
      "2019-04-15 16:44:12,597 DEV  : loss 14.34126949 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:44:14,135 TEST : loss 14.20361233 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:44:14,174 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:44:14,454 epoch 15 - iter 0/38 - loss 17.45547485\n",
      "2019-04-15 16:44:15,625 epoch 15 - iter 3/38 - loss 15.51143026\n",
      "2019-04-15 16:44:16,947 epoch 15 - iter 6/38 - loss 18.17329884\n",
      "2019-04-15 16:44:18,026 epoch 15 - iter 9/38 - loss 16.67150173\n",
      "2019-04-15 16:44:18,906 epoch 15 - iter 12/38 - loss 16.05094631\n",
      "2019-04-15 16:44:19,900 epoch 15 - iter 15/38 - loss 15.80949938\n",
      "2019-04-15 16:44:20,974 epoch 15 - iter 18/38 - loss 16.13229716\n",
      "2019-04-15 16:44:21,981 epoch 15 - iter 21/38 - loss 16.01069663\n",
      "2019-04-15 16:44:22,800 epoch 15 - iter 24/38 - loss 15.35016933\n",
      "2019-04-15 16:44:23,925 epoch 15 - iter 27/38 - loss 15.47139464\n",
      "2019-04-15 16:44:24,777 epoch 15 - iter 30/38 - loss 15.51871214\n",
      "2019-04-15 16:44:25,796 epoch 15 - iter 33/38 - loss 15.49139974\n",
      "2019-04-15 16:44:26,827 epoch 15 - iter 36/38 - loss 15.43655282\n",
      "2019-04-15 16:44:27,564 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:44:27,566 EPOCH 15 done: loss 15.5791 - lr 0.0250 - bad epochs 0\n",
      "2019-04-15 16:44:30,823 DEV  : loss 14.49373341 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:44:32,380 TEST : loss 14.54314709 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:44:32,420 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:44:32,761 epoch 16 - iter 0/38 - loss 12.17839050\n",
      "2019-04-15 16:44:33,633 epoch 16 - iter 3/38 - loss 12.89774609\n",
      "2019-04-15 16:44:34,847 epoch 16 - iter 6/38 - loss 16.83308765\n",
      "2019-04-15 16:44:35,807 epoch 16 - iter 9/38 - loss 16.19202461\n",
      "2019-04-15 16:44:36,757 epoch 16 - iter 12/38 - loss 15.86765524\n",
      "2019-04-15 16:44:38,205 epoch 16 - iter 15/38 - loss 16.08711696\n",
      "2019-04-15 16:44:39,039 epoch 16 - iter 18/38 - loss 15.76249128\n",
      "2019-04-15 16:44:39,938 epoch 16 - iter 21/38 - loss 15.81606176\n",
      "2019-04-15 16:44:40,795 epoch 16 - iter 24/38 - loss 15.36376278\n",
      "2019-04-15 16:44:41,899 epoch 16 - iter 27/38 - loss 15.42081411\n",
      "2019-04-15 16:44:42,971 epoch 16 - iter 30/38 - loss 15.40411894\n",
      "2019-04-15 16:44:44,203 epoch 16 - iter 33/38 - loss 15.38726478\n",
      "2019-04-15 16:44:45,247 epoch 16 - iter 36/38 - loss 15.56798917\n",
      "2019-04-15 16:44:45,451 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:44:45,453 EPOCH 16 done: loss 15.5710 - lr 0.0250 - bad epochs 0\n",
      "2019-04-15 16:44:48,598 DEV  : loss 14.43402576 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:44:50,148 TEST : loss 14.54358101 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:44:50,188 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:44:50,426 epoch 17 - iter 0/38 - loss 11.98373222\n",
      "2019-04-15 16:44:51,786 epoch 17 - iter 3/38 - loss 15.90095496\n",
      "2019-04-15 16:44:52,632 epoch 17 - iter 6/38 - loss 15.43650164\n",
      "2019-04-15 16:44:53,643 epoch 17 - iter 9/38 - loss 15.23457298\n",
      "2019-04-15 16:44:54,787 epoch 17 - iter 12/38 - loss 15.41333125\n",
      "2019-04-15 16:44:55,788 epoch 17 - iter 15/38 - loss 15.50092804\n",
      "2019-04-15 16:44:56,588 epoch 17 - iter 18/38 - loss 15.48420018\n",
      "2019-04-15 16:44:57,690 epoch 17 - iter 21/38 - loss 15.63914850\n",
      "2019-04-15 16:44:58,718 epoch 17 - iter 24/38 - loss 15.85020824\n",
      "2019-04-15 16:44:59,707 epoch 17 - iter 27/38 - loss 15.70513841\n",
      "2019-04-15 16:45:00,667 epoch 17 - iter 30/38 - loss 15.60388507\n",
      "2019-04-15 16:45:02,025 epoch 17 - iter 33/38 - loss 16.36448184\n",
      "2019-04-15 16:45:02,951 epoch 17 - iter 36/38 - loss 16.20420015\n",
      "2019-04-15 16:45:03,240 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:45:03,241 EPOCH 17 done: loss 16.2802 - lr 0.0250 - bad epochs 0\n",
      "2019-04-15 16:45:06,364 DEV  : loss 14.74485207 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:45:07,915 TEST : loss 14.58670712 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:45:07,917 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:45:08,222 epoch 18 - iter 0/38 - loss 19.50077057\n",
      "2019-04-15 16:45:09,100 epoch 18 - iter 3/38 - loss 16.29261184\n",
      "2019-04-15 16:45:09,989 epoch 18 - iter 6/38 - loss 15.54609939\n",
      "2019-04-15 16:45:11,355 epoch 18 - iter 9/38 - loss 17.74729033\n",
      "2019-04-15 16:45:12,342 epoch 18 - iter 12/38 - loss 17.66867264\n",
      "2019-04-15 16:45:13,462 epoch 18 - iter 15/38 - loss 17.76418936\n",
      "2019-04-15 16:45:14,549 epoch 18 - iter 18/38 - loss 17.25868371\n",
      "2019-04-15 16:45:15,507 epoch 18 - iter 21/38 - loss 16.64309107\n",
      "2019-04-15 16:45:16,428 epoch 18 - iter 24/38 - loss 16.46166485\n",
      "2019-04-15 16:45:17,982 epoch 18 - iter 27/38 - loss 16.60371007\n",
      "2019-04-15 16:45:18,803 epoch 18 - iter 30/38 - loss 16.68296620\n",
      "2019-04-15 16:45:20,049 epoch 18 - iter 33/38 - loss 16.47248139\n",
      "2019-04-15 16:45:20,963 epoch 18 - iter 36/38 - loss 16.14473500\n",
      "2019-04-15 16:45:21,225 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:45:21,226 EPOCH 18 done: loss 16.1094 - lr 0.0250 - bad epochs 1\n",
      "2019-04-15 16:45:24,580 DEV  : loss 14.83877468 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:45:26,118 TEST : loss 14.84499168 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:45:26,120 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:45:26,431 epoch 19 - iter 0/38 - loss 19.37992668\n",
      "2019-04-15 16:45:27,486 epoch 19 - iter 3/38 - loss 16.80682445\n",
      "2019-04-15 16:45:28,919 epoch 19 - iter 6/38 - loss 19.57986205\n",
      "2019-04-15 16:45:29,852 epoch 19 - iter 9/38 - loss 17.94014578\n",
      "2019-04-15 16:45:30,706 epoch 19 - iter 12/38 - loss 17.25710884\n",
      "2019-04-15 16:45:31,808 epoch 19 - iter 15/38 - loss 16.91911411\n",
      "2019-04-15 16:45:32,919 epoch 19 - iter 18/38 - loss 17.01453801\n",
      "2019-04-15 16:45:33,781 epoch 19 - iter 21/38 - loss 16.77705531\n",
      "2019-04-15 16:45:34,940 epoch 19 - iter 24/38 - loss 16.57710899\n",
      "2019-04-15 16:45:35,937 epoch 19 - iter 27/38 - loss 16.58891678\n",
      "2019-04-15 16:45:36,845 epoch 19 - iter 30/38 - loss 16.59972179\n",
      "2019-04-15 16:45:38,060 epoch 19 - iter 33/38 - loss 16.44475892\n",
      "2019-04-15 16:45:38,839 epoch 19 - iter 36/38 - loss 16.06188596\n",
      "2019-04-15 16:45:39,085 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:45:39,087 EPOCH 19 done: loss 16.0569 - lr 0.0250 - bad epochs 2\n",
      "2019-04-15 16:45:42,278 DEV  : loss 15.13339043 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:45:43,843 TEST : loss 14.63087082 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:45:43,845 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:45:44,182 epoch 20 - iter 0/38 - loss 11.16577721\n",
      "2019-04-15 16:45:45,340 epoch 20 - iter 3/38 - loss 14.91509295\n",
      "2019-04-15 16:45:46,374 epoch 20 - iter 6/38 - loss 16.05635071\n",
      "2019-04-15 16:45:47,427 epoch 20 - iter 9/38 - loss 15.98658276\n",
      "2019-04-15 16:45:48,393 epoch 20 - iter 12/38 - loss 15.47320513\n",
      "2019-04-15 16:45:49,263 epoch 20 - iter 15/38 - loss 15.24319863\n",
      "2019-04-15 16:45:50,111 epoch 20 - iter 18/38 - loss 15.15692661\n",
      "2019-04-15 16:45:51,301 epoch 20 - iter 21/38 - loss 15.17263282\n",
      "2019-04-15 16:45:52,681 epoch 20 - iter 24/38 - loss 15.38073666\n",
      "2019-04-15 16:45:53,848 epoch 20 - iter 27/38 - loss 16.07152479\n",
      "2019-04-15 16:45:54,878 epoch 20 - iter 30/38 - loss 16.19372506\n",
      "2019-04-15 16:45:55,669 epoch 20 - iter 33/38 - loss 15.91102712\n",
      "2019-04-15 16:45:56,558 epoch 20 - iter 36/38 - loss 15.66512523\n",
      "2019-04-15 16:45:56,805 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:45:56,806 EPOCH 20 done: loss 15.6455 - lr 0.0250 - bad epochs 3\n",
      "2019-04-15 16:46:00,004 DEV  : loss 14.43134689 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:46:01,585 TEST : loss 14.42472172 - f-score 0.0000 - acc 0.0000\n",
      "Epoch    19: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2019-04-15 16:46:01,587 Epoch 19: reducing weight decay factor of group 0 to 1.2500e-02.\n",
      "2019-04-15 16:46:01,588 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:46:01,897 epoch 21 - iter 0/38 - loss 11.06369305\n",
      "2019-04-15 16:46:03,357 epoch 21 - iter 3/38 - loss 15.64430356\n",
      "2019-04-15 16:46:04,538 epoch 21 - iter 6/38 - loss 16.18060984\n",
      "2019-04-15 16:46:05,484 epoch 21 - iter 9/38 - loss 15.78704033\n",
      "2019-04-15 16:46:06,470 epoch 21 - iter 12/38 - loss 15.72998802\n",
      "2019-04-15 16:46:07,456 epoch 21 - iter 15/38 - loss 15.04492378\n",
      "2019-04-15 16:46:08,336 epoch 21 - iter 18/38 - loss 15.02366688\n",
      "2019-04-15 16:46:09,644 epoch 21 - iter 21/38 - loss 15.43303126\n",
      "2019-04-15 16:46:10,676 epoch 21 - iter 24/38 - loss 15.56757851\n",
      "2019-04-15 16:46:11,541 epoch 21 - iter 27/38 - loss 15.46669272\n",
      "2019-04-15 16:46:12,635 epoch 21 - iter 30/38 - loss 15.67184707\n",
      "2019-04-15 16:46:13,606 epoch 21 - iter 33/38 - loss 15.59351071\n",
      "2019-04-15 16:46:14,485 epoch 21 - iter 36/38 - loss 15.28409615\n",
      "2019-04-15 16:46:14,837 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:46:14,838 EPOCH 21 done: loss 15.3571 - lr 0.0125 - bad epochs 0\n",
      "2019-04-15 16:46:17,947 DEV  : loss 14.43808651 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:46:19,463 TEST : loss 14.38084602 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:46:19,501 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:46:19,724 epoch 22 - iter 0/38 - loss 13.84498978\n",
      "2019-04-15 16:46:20,877 epoch 22 - iter 3/38 - loss 17.71273661\n",
      "2019-04-15 16:46:22,255 epoch 22 - iter 6/38 - loss 17.22614288\n",
      "2019-04-15 16:46:23,049 epoch 22 - iter 9/38 - loss 16.17570086\n",
      "2019-04-15 16:46:24,120 epoch 22 - iter 12/38 - loss 16.36034870\n",
      "2019-04-15 16:46:25,011 epoch 22 - iter 15/38 - loss 15.77741718\n",
      "2019-04-15 16:46:26,004 epoch 22 - iter 18/38 - loss 15.63572743\n",
      "2019-04-15 16:46:26,846 epoch 22 - iter 21/38 - loss 15.42432586\n",
      "2019-04-15 16:46:27,865 epoch 22 - iter 24/38 - loss 15.23757786\n",
      "2019-04-15 16:46:29,078 epoch 22 - iter 27/38 - loss 15.21415690\n",
      "2019-04-15 16:46:30,198 epoch 22 - iter 30/38 - loss 15.16147761\n",
      "2019-04-15 16:46:31,264 epoch 22 - iter 33/38 - loss 15.23238053\n",
      "2019-04-15 16:46:32,367 epoch 22 - iter 36/38 - loss 15.23965678\n",
      "2019-04-15 16:46:32,645 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:46:32,647 EPOCH 22 done: loss 15.2562 - lr 0.0125 - bad epochs 0\n",
      "2019-04-15 16:46:35,806 DEV  : loss 14.17571163 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:46:37,377 TEST : loss 13.87386131 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:46:37,418 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:46:37,810 epoch 23 - iter 0/38 - loss 18.23908043\n",
      "2019-04-15 16:46:38,789 epoch 23 - iter 3/38 - loss 15.74036646\n",
      "2019-04-15 16:46:39,846 epoch 23 - iter 6/38 - loss 14.50946999\n",
      "2019-04-15 16:46:41,007 epoch 23 - iter 9/38 - loss 16.09089937\n",
      "2019-04-15 16:46:42,159 epoch 23 - iter 12/38 - loss 15.98020370\n",
      "2019-04-15 16:46:43,172 epoch 23 - iter 15/38 - loss 15.63670838\n",
      "2019-04-15 16:46:44,210 epoch 23 - iter 18/38 - loss 15.56363141\n",
      "2019-04-15 16:46:45,137 epoch 23 - iter 21/38 - loss 15.19683426\n",
      "2019-04-15 16:46:46,149 epoch 23 - iter 24/38 - loss 15.20476288\n",
      "2019-04-15 16:46:47,753 epoch 23 - iter 27/38 - loss 15.39754360\n",
      "2019-04-15 16:46:48,609 epoch 23 - iter 30/38 - loss 15.35643642\n",
      "2019-04-15 16:46:49,406 epoch 23 - iter 33/38 - loss 15.05762238\n",
      "2019-04-15 16:46:50,569 epoch 23 - iter 36/38 - loss 15.30287039\n",
      "2019-04-15 16:46:50,751 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:46:50,752 EPOCH 23 done: loss 15.2710 - lr 0.0125 - bad epochs 0\n",
      "2019-04-15 16:46:53,959 DEV  : loss 14.34815788 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:46:55,488 TEST : loss 14.03157139 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:46:55,490 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:46:55,759 epoch 24 - iter 0/38 - loss 11.82587433\n",
      "2019-04-15 16:46:56,773 epoch 24 - iter 3/38 - loss 14.50293303\n",
      "2019-04-15 16:46:57,702 epoch 24 - iter 6/38 - loss 13.53582137\n",
      "2019-04-15 16:46:58,579 epoch 24 - iter 9/38 - loss 13.50333214\n",
      "2019-04-15 16:46:59,574 epoch 24 - iter 12/38 - loss 13.88116169\n",
      "2019-04-15 16:47:01,163 epoch 24 - iter 15/38 - loss 14.58531541\n",
      "2019-04-15 16:47:02,346 epoch 24 - iter 18/38 - loss 15.41674775\n",
      "2019-04-15 16:47:03,248 epoch 24 - iter 21/38 - loss 15.22307682\n",
      "2019-04-15 16:47:04,006 epoch 24 - iter 24/38 - loss 15.01484825\n",
      "2019-04-15 16:47:05,014 epoch 24 - iter 27/38 - loss 15.05070462\n",
      "2019-04-15 16:47:06,199 epoch 24 - iter 30/38 - loss 15.12677150\n",
      "2019-04-15 16:47:07,272 epoch 24 - iter 33/38 - loss 15.25657250\n",
      "2019-04-15 16:47:08,362 epoch 24 - iter 36/38 - loss 15.02345967\n",
      "2019-04-15 16:47:08,699 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:47:08,700 EPOCH 24 done: loss 15.1577 - lr 0.0125 - bad epochs 1\n",
      "2019-04-15 16:47:11,888 DEV  : loss 14.04233456 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:47:13,428 TEST : loss 13.83449078 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:47:13,468 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:47:13,829 epoch 25 - iter 0/38 - loss 15.20037842\n",
      "2019-04-15 16:47:14,807 epoch 25 - iter 3/38 - loss 13.87319827\n",
      "2019-04-15 16:47:15,798 epoch 25 - iter 6/38 - loss 14.84294987\n",
      "2019-04-15 16:47:17,317 epoch 25 - iter 9/38 - loss 15.25426588\n",
      "2019-04-15 16:47:18,628 epoch 25 - iter 12/38 - loss 17.12666812\n",
      "2019-04-15 16:47:19,549 epoch 25 - iter 15/38 - loss 16.41109759\n",
      "2019-04-15 16:47:20,482 epoch 25 - iter 18/38 - loss 16.07994923\n",
      "2019-04-15 16:47:21,429 epoch 25 - iter 21/38 - loss 15.92874479\n",
      "2019-04-15 16:47:22,419 epoch 25 - iter 24/38 - loss 15.44267143\n",
      "2019-04-15 16:47:23,481 epoch 25 - iter 27/38 - loss 15.50581431\n",
      "2019-04-15 16:47:24,459 epoch 25 - iter 30/38 - loss 15.57977178\n",
      "2019-04-15 16:47:25,304 epoch 25 - iter 33/38 - loss 15.25038478\n",
      "2019-04-15 16:47:26,314 epoch 25 - iter 36/38 - loss 15.27884308\n",
      "2019-04-15 16:47:26,541 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:47:26,543 EPOCH 25 done: loss 15.3018 - lr 0.0125 - bad epochs 0\n",
      "2019-04-15 16:47:29,760 DEV  : loss 14.08981037 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:47:31,351 TEST : loss 13.91807365 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:47:31,353 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:47:31,676 epoch 26 - iter 0/38 - loss 20.31930542\n",
      "2019-04-15 16:47:32,747 epoch 26 - iter 3/38 - loss 16.01763105\n",
      "2019-04-15 16:47:34,021 epoch 26 - iter 6/38 - loss 15.08690371\n",
      "2019-04-15 16:47:35,000 epoch 26 - iter 9/38 - loss 14.68676834\n",
      "2019-04-15 16:47:36,018 epoch 26 - iter 12/38 - loss 14.63909501\n",
      "2019-04-15 16:47:36,949 epoch 26 - iter 15/38 - loss 14.73262501\n",
      "2019-04-15 16:47:37,922 epoch 26 - iter 18/38 - loss 15.34962624\n",
      "2019-04-15 16:47:39,462 epoch 26 - iter 21/38 - loss 15.78292222\n",
      "2019-04-15 16:47:40,517 epoch 26 - iter 24/38 - loss 15.52342793\n",
      "2019-04-15 16:47:41,547 epoch 26 - iter 27/38 - loss 15.34199303\n",
      "2019-04-15 16:47:42,516 epoch 26 - iter 30/38 - loss 15.18490490\n",
      "2019-04-15 16:47:43,719 epoch 26 - iter 33/38 - loss 15.79170120\n",
      "2019-04-15 16:47:44,709 epoch 26 - iter 36/38 - loss 15.44947771\n",
      "2019-04-15 16:47:44,981 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:47:44,982 EPOCH 26 done: loss 15.4221 - lr 0.0125 - bad epochs 1\n",
      "2019-04-15 16:47:48,172 DEV  : loss 14.55919266 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:47:49,735 TEST : loss 14.20692539 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:47:49,737 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:47:50,022 epoch 27 - iter 0/38 - loss 14.22393990\n",
      "2019-04-15 16:47:51,114 epoch 27 - iter 3/38 - loss 14.52633667\n",
      "2019-04-15 16:47:52,241 epoch 27 - iter 6/38 - loss 16.36329106\n",
      "2019-04-15 16:47:53,046 epoch 27 - iter 9/38 - loss 15.32963009\n",
      "2019-04-15 16:47:53,953 epoch 27 - iter 12/38 - loss 15.22517080\n",
      "2019-04-15 16:47:54,882 epoch 27 - iter 15/38 - loss 14.91548353\n",
      "2019-04-15 16:47:55,810 epoch 27 - iter 18/38 - loss 14.82622704\n",
      "2019-04-15 16:47:56,829 epoch 27 - iter 21/38 - loss 14.64471674\n",
      "2019-04-15 16:47:58,230 epoch 27 - iter 24/38 - loss 14.87327877\n",
      "2019-04-15 16:47:59,781 epoch 27 - iter 27/38 - loss 15.70453252\n",
      "2019-04-15 16:48:00,641 epoch 27 - iter 30/38 - loss 15.43675001\n",
      "2019-04-15 16:48:01,674 epoch 27 - iter 33/38 - loss 15.22586166\n",
      "2019-04-15 16:48:02,699 epoch 27 - iter 36/38 - loss 15.26347805\n",
      "2019-04-15 16:48:03,026 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:48:03,027 EPOCH 27 done: loss 15.2892 - lr 0.0125 - bad epochs 2\n",
      "2019-04-15 16:48:06,242 DEV  : loss 14.51306629 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:48:07,806 TEST : loss 14.24169445 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:48:07,808 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:48:08,081 epoch 28 - iter 0/38 - loss 13.73062515\n",
      "2019-04-15 16:48:08,907 epoch 28 - iter 3/38 - loss 13.25482297\n",
      "2019-04-15 16:48:09,973 epoch 28 - iter 6/38 - loss 13.60009302\n",
      "2019-04-15 16:48:11,552 epoch 28 - iter 9/38 - loss 14.14857426\n",
      "2019-04-15 16:48:12,490 epoch 28 - iter 12/38 - loss 14.42983429\n",
      "2019-04-15 16:48:13,494 epoch 28 - iter 15/38 - loss 14.59480762\n",
      "2019-04-15 16:48:14,520 epoch 28 - iter 18/38 - loss 14.62866798\n",
      "2019-04-15 16:48:15,600 epoch 28 - iter 21/38 - loss 14.57300329\n",
      "2019-04-15 16:48:16,763 epoch 28 - iter 24/38 - loss 14.47116688\n",
      "2019-04-15 16:48:17,745 epoch 28 - iter 27/38 - loss 14.53750702\n",
      "2019-04-15 16:48:18,791 epoch 28 - iter 30/38 - loss 14.61105833\n",
      "2019-04-15 16:48:19,916 epoch 28 - iter 33/38 - loss 14.89381246\n",
      "2019-04-15 16:48:21,140 epoch 28 - iter 36/38 - loss 15.22719017\n",
      "2019-04-15 16:48:21,340 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:48:21,341 EPOCH 28 done: loss 15.2260 - lr 0.0125 - bad epochs 3\n",
      "2019-04-15 16:48:25,785 DEV  : loss 14.38864899 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:48:27,329 TEST : loss 14.12607193 - f-score 0.0000 - acc 0.0000\n",
      "Epoch    27: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2019-04-15 16:48:27,331 Epoch 27: reducing weight decay factor of group 0 to 6.2500e-03.\n",
      "2019-04-15 16:48:27,333 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:48:27,671 epoch 29 - iter 0/38 - loss 12.24544239\n",
      "2019-04-15 16:48:28,716 epoch 29 - iter 3/38 - loss 13.49829435\n",
      "2019-04-15 16:48:29,920 epoch 29 - iter 6/38 - loss 15.08902659\n",
      "2019-04-15 16:48:31,223 epoch 29 - iter 9/38 - loss 14.56094131\n",
      "2019-04-15 16:48:32,178 epoch 29 - iter 12/38 - loss 14.32935781\n",
      "2019-04-15 16:48:32,963 epoch 29 - iter 15/38 - loss 14.29893816\n",
      "2019-04-15 16:48:33,781 epoch 29 - iter 18/38 - loss 14.13540012\n",
      "2019-04-15 16:48:34,693 epoch 29 - iter 21/38 - loss 14.02271626\n",
      "2019-04-15 16:48:35,747 epoch 29 - iter 24/38 - loss 14.43027649\n",
      "2019-04-15 16:48:36,675 epoch 29 - iter 27/38 - loss 14.40981245\n",
      "2019-04-15 16:48:37,836 epoch 29 - iter 30/38 - loss 14.51541470\n",
      "2019-04-15 16:48:38,991 epoch 29 - iter 33/38 - loss 14.65649571\n",
      "2019-04-15 16:48:40,349 epoch 29 - iter 36/38 - loss 15.12907763\n",
      "2019-04-15 16:48:40,565 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:48:40,566 EPOCH 29 done: loss 15.1344 - lr 0.0063 - bad epochs 0\n",
      "2019-04-15 16:48:43,824 DEV  : loss 14.02432251 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:48:45,394 TEST : loss 13.79748154 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:48:45,433 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:48:45,788 epoch 30 - iter 0/38 - loss 17.75629044\n",
      "2019-04-15 16:48:46,701 epoch 30 - iter 3/38 - loss 13.92581344\n",
      "2019-04-15 16:48:47,662 epoch 30 - iter 6/38 - loss 14.29428823\n",
      "2019-04-15 16:48:48,800 epoch 30 - iter 9/38 - loss 15.11748533\n",
      "2019-04-15 16:48:49,821 epoch 30 - iter 12/38 - loss 14.94137500\n",
      "2019-04-15 16:48:50,963 epoch 30 - iter 15/38 - loss 15.47188568\n",
      "2019-04-15 16:48:51,740 epoch 30 - iter 18/38 - loss 15.10672609\n",
      "2019-04-15 16:48:52,763 epoch 30 - iter 21/38 - loss 15.28457633\n",
      "2019-04-15 16:48:53,876 epoch 30 - iter 24/38 - loss 15.22153530\n",
      "2019-04-15 16:48:55,270 epoch 30 - iter 27/38 - loss 15.06616609\n",
      "2019-04-15 16:48:56,169 epoch 30 - iter 30/38 - loss 14.79568869\n",
      "2019-04-15 16:48:57,486 epoch 30 - iter 33/38 - loss 15.01428004\n",
      "2019-04-15 16:48:58,476 epoch 30 - iter 36/38 - loss 14.91375792\n",
      "2019-04-15 16:48:58,678 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:48:58,680 EPOCH 30 done: loss 14.9650 - lr 0.0063 - bad epochs 0\n",
      "2019-04-15 16:49:01,837 DEV  : loss 13.84596920 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:49:03,407 TEST : loss 13.63988972 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:49:03,446 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:49:03,761 epoch 31 - iter 0/38 - loss 12.49384689\n",
      "2019-04-15 16:49:04,900 epoch 31 - iter 3/38 - loss 14.56739259\n",
      "2019-04-15 16:49:05,917 epoch 31 - iter 6/38 - loss 14.23214258\n",
      "2019-04-15 16:49:06,855 epoch 31 - iter 9/38 - loss 14.37513618\n",
      "2019-04-15 16:49:07,698 epoch 31 - iter 12/38 - loss 14.58495316\n",
      "2019-04-15 16:49:08,525 epoch 31 - iter 15/38 - loss 14.21288353\n",
      "2019-04-15 16:49:09,583 epoch 31 - iter 18/38 - loss 14.32037484\n",
      "2019-04-15 16:49:10,798 epoch 31 - iter 21/38 - loss 14.84980163\n",
      "2019-04-15 16:49:11,659 epoch 31 - iter 24/38 - loss 14.70359951\n",
      "2019-04-15 16:49:12,582 epoch 31 - iter 27/38 - loss 14.54688716\n",
      "2019-04-15 16:49:14,246 epoch 31 - iter 30/38 - loss 14.88973211\n",
      "2019-04-15 16:49:15,298 epoch 31 - iter 33/38 - loss 14.86586868\n",
      "2019-04-15 16:49:16,203 epoch 31 - iter 36/38 - loss 14.80850789\n",
      "2019-04-15 16:49:16,362 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:49:16,363 EPOCH 31 done: loss 14.7695 - lr 0.0063 - bad epochs 0\n",
      "2019-04-15 16:49:19,553 DEV  : loss 13.85795593 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:49:21,122 TEST : loss 13.74889565 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:49:21,161 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:49:21,523 epoch 32 - iter 0/38 - loss 15.90988159\n",
      "2019-04-15 16:49:22,491 epoch 32 - iter 3/38 - loss 12.60913205\n",
      "2019-04-15 16:49:23,364 epoch 32 - iter 6/38 - loss 12.68181079\n",
      "2019-04-15 16:49:24,281 epoch 32 - iter 9/38 - loss 14.19787550\n",
      "2019-04-15 16:49:25,316 epoch 32 - iter 12/38 - loss 14.38364645\n",
      "2019-04-15 16:49:26,435 epoch 32 - iter 15/38 - loss 14.29991496\n",
      "2019-04-15 16:49:27,538 epoch 32 - iter 18/38 - loss 14.31195259\n",
      "2019-04-15 16:49:28,477 epoch 32 - iter 21/38 - loss 14.09964249\n",
      "2019-04-15 16:49:29,695 epoch 32 - iter 24/38 - loss 15.03383076\n",
      "2019-04-15 16:49:30,776 epoch 32 - iter 27/38 - loss 15.00467035\n",
      "2019-04-15 16:49:32,217 epoch 32 - iter 30/38 - loss 15.02126552\n",
      "2019-04-15 16:49:32,976 epoch 32 - iter 33/38 - loss 14.82146732\n",
      "2019-04-15 16:49:33,900 epoch 32 - iter 36/38 - loss 14.70596955\n",
      "2019-04-15 16:49:34,193 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:49:34,194 EPOCH 32 done: loss 14.7317 - lr 0.0063 - bad epochs 0\n",
      "2019-04-15 16:49:37,361 DEV  : loss 13.69151402 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:49:38,899 TEST : loss 13.51465797 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:49:38,939 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:49:39,233 epoch 33 - iter 0/38 - loss 13.72683907\n",
      "2019-04-15 16:49:40,162 epoch 33 - iter 3/38 - loss 13.46806622\n",
      "2019-04-15 16:49:41,310 epoch 33 - iter 6/38 - loss 14.00879615\n",
      "2019-04-15 16:49:42,372 epoch 33 - iter 9/38 - loss 14.80256443\n",
      "2019-04-15 16:49:43,237 epoch 33 - iter 12/38 - loss 14.61379352\n",
      "2019-04-15 16:49:44,227 epoch 33 - iter 15/38 - loss 14.47698754\n",
      "2019-04-15 16:49:45,222 epoch 33 - iter 18/38 - loss 14.37129302\n",
      "2019-04-15 16:49:46,520 epoch 33 - iter 21/38 - loss 14.59487880\n",
      "2019-04-15 16:49:47,916 epoch 33 - iter 24/38 - loss 15.22544567\n",
      "2019-04-15 16:49:48,980 epoch 33 - iter 27/38 - loss 15.28517686\n",
      "2019-04-15 16:49:49,760 epoch 33 - iter 30/38 - loss 14.97401185\n",
      "2019-04-15 16:49:50,647 epoch 33 - iter 33/38 - loss 14.74964826\n",
      "2019-04-15 16:49:52,030 epoch 33 - iter 36/38 - loss 14.86089541\n",
      "2019-04-15 16:49:52,288 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:49:52,289 EPOCH 33 done: loss 14.8251 - lr 0.0063 - bad epochs 0\n",
      "2019-04-15 16:49:55,535 DEV  : loss 13.97054863 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:49:57,102 TEST : loss 13.74471188 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:49:57,104 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:49:57,438 epoch 34 - iter 0/38 - loss 14.28672028\n",
      "2019-04-15 16:49:58,621 epoch 34 - iter 3/38 - loss 15.53660703\n",
      "2019-04-15 16:49:59,634 epoch 34 - iter 6/38 - loss 15.55823367\n",
      "2019-04-15 16:50:00,865 epoch 34 - iter 9/38 - loss 16.76699200\n",
      "2019-04-15 16:50:01,672 epoch 34 - iter 12/38 - loss 15.67126472\n",
      "2019-04-15 16:50:02,507 epoch 34 - iter 15/38 - loss 15.38392866\n",
      "2019-04-15 16:50:04,053 epoch 34 - iter 18/38 - loss 15.37598088\n",
      "2019-04-15 16:50:05,098 epoch 34 - iter 21/38 - loss 15.40110731\n",
      "2019-04-15 16:50:05,927 epoch 34 - iter 24/38 - loss 14.80261572\n",
      "2019-04-15 16:50:07,056 epoch 34 - iter 27/38 - loss 15.03651536\n",
      "2019-04-15 16:50:07,982 epoch 34 - iter 30/38 - loss 14.84463309\n",
      "2019-04-15 16:50:08,973 epoch 34 - iter 33/38 - loss 14.73918324\n",
      "2019-04-15 16:50:10,034 epoch 34 - iter 36/38 - loss 14.72036193\n",
      "2019-04-15 16:50:10,277 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:50:10,278 EPOCH 34 done: loss 14.7522 - lr 0.0063 - bad epochs 1\n",
      "2019-04-15 16:50:13,447 DEV  : loss 13.87041664 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:50:15,032 TEST : loss 13.80192471 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:50:15,035 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:50:15,341 epoch 35 - iter 0/38 - loss 17.27988052\n",
      "2019-04-15 16:50:16,770 epoch 35 - iter 3/38 - loss 20.01498604\n",
      "2019-04-15 16:50:17,601 epoch 35 - iter 6/38 - loss 16.99156216\n",
      "2019-04-15 16:50:18,713 epoch 35 - iter 9/38 - loss 16.74427166\n",
      "2019-04-15 16:50:19,665 epoch 35 - iter 12/38 - loss 16.02262490\n",
      "2019-04-15 16:50:21,010 epoch 35 - iter 15/38 - loss 15.74933237\n",
      "2019-04-15 16:50:21,943 epoch 35 - iter 18/38 - loss 15.31527188\n",
      "2019-04-15 16:50:22,972 epoch 35 - iter 21/38 - loss 15.01480944\n",
      "2019-04-15 16:50:23,975 epoch 35 - iter 24/38 - loss 14.68149776\n",
      "2019-04-15 16:50:25,108 epoch 35 - iter 27/38 - loss 14.69860111\n",
      "2019-04-15 16:50:26,147 epoch 35 - iter 30/38 - loss 14.75330113\n",
      "2019-04-15 16:50:27,282 epoch 35 - iter 33/38 - loss 14.81861866\n",
      "2019-04-15 16:50:28,373 epoch 35 - iter 36/38 - loss 14.71147465\n",
      "2019-04-15 16:50:28,633 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:50:28,634 EPOCH 35 done: loss 14.7371 - lr 0.0063 - bad epochs 2\n",
      "2019-04-15 16:50:31,869 DEV  : loss 13.74672031 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:50:33,477 TEST : loss 13.73607731 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:50:33,479 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:50:34,259 epoch 36 - iter 0/38 - loss 21.87456131\n",
      "2019-04-15 16:50:35,205 epoch 36 - iter 3/38 - loss 16.83476472\n",
      "2019-04-15 16:50:36,025 epoch 36 - iter 6/38 - loss 15.17695863\n",
      "2019-04-15 16:50:36,936 epoch 36 - iter 9/38 - loss 14.46273060\n",
      "2019-04-15 16:50:37,902 epoch 36 - iter 12/38 - loss 13.94170460\n",
      "2019-04-15 16:50:39,155 epoch 36 - iter 15/38 - loss 14.86365306\n",
      "2019-04-15 16:50:40,137 epoch 36 - iter 18/38 - loss 14.65912839\n",
      "2019-04-15 16:50:41,222 epoch 36 - iter 21/38 - loss 15.04433146\n",
      "2019-04-15 16:50:42,480 epoch 36 - iter 24/38 - loss 15.38397999\n",
      "2019-04-15 16:50:43,358 epoch 36 - iter 27/38 - loss 15.18264232\n",
      "2019-04-15 16:50:44,388 epoch 36 - iter 30/38 - loss 15.00621823\n",
      "2019-04-15 16:50:45,230 epoch 36 - iter 33/38 - loss 14.98784472\n",
      "2019-04-15 16:50:46,148 epoch 36 - iter 36/38 - loss 14.80606816\n",
      "2019-04-15 16:50:46,510 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:50:46,512 EPOCH 36 done: loss 14.8372 - lr 0.0063 - bad epochs 3\n",
      "2019-04-15 16:50:49,722 DEV  : loss 13.74272919 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:50:51,288 TEST : loss 13.74473476 - f-score 0.0000 - acc 0.0000\n",
      "Epoch    35: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2019-04-15 16:50:51,291 Epoch 35: reducing weight decay factor of group 0 to 3.1250e-03.\n",
      "2019-04-15 16:50:51,292 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:50:51,507 epoch 37 - iter 0/38 - loss 11.52225304\n",
      "2019-04-15 16:50:52,616 epoch 37 - iter 3/38 - loss 13.99866819\n",
      "2019-04-15 16:50:53,585 epoch 37 - iter 6/38 - loss 14.15788351\n",
      "2019-04-15 16:50:54,590 epoch 37 - iter 9/38 - loss 14.39667940\n",
      "2019-04-15 16:50:55,508 epoch 37 - iter 12/38 - loss 14.21508987\n",
      "2019-04-15 16:50:56,547 epoch 37 - iter 15/38 - loss 14.10369158\n",
      "2019-04-15 16:50:58,206 epoch 37 - iter 18/38 - loss 15.28750053\n",
      "2019-04-15 16:50:59,174 epoch 37 - iter 21/38 - loss 15.11832762\n",
      "2019-04-15 16:51:00,104 epoch 37 - iter 24/38 - loss 15.05153198\n",
      "2019-04-15 16:51:01,206 epoch 37 - iter 27/38 - loss 14.98389421\n",
      "2019-04-15 16:51:02,237 epoch 37 - iter 30/38 - loss 15.06953283\n",
      "2019-04-15 16:51:03,178 epoch 37 - iter 33/38 - loss 14.94416587\n",
      "2019-04-15 16:51:04,145 epoch 37 - iter 36/38 - loss 14.71306522\n",
      "2019-04-15 16:51:04,406 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:51:04,407 EPOCH 37 done: loss 14.7394 - lr 0.0031 - bad epochs 0\n",
      "2019-04-15 16:51:07,680 DEV  : loss 13.50305939 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:51:09,268 TEST : loss 13.40990829 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-15 16:51:09,270 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:51:09,536 epoch 38 - iter 0/38 - loss 14.02747059\n",
      "2019-04-15 16:51:10,442 epoch 38 - iter 3/38 - loss 12.49120235\n",
      "2019-04-15 16:51:10,903 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:51:10,908 Exiting from training early.\n",
      "2019-04-15 16:51:10,909 Saving model ...\n",
      "2019-04-15 16:51:10,963 Done.\n",
      "2019-04-15 16:51:10,964 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-15 16:51:10,965 Testing using best model ...\n",
      "2019-04-15 16:51:10,967 loading file /home/jupyter/result_char_only/best-model.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c7f9200ba244>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m               \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m               checkpoint=False)\n\u001b[0m",
      "\u001b[0;32m~/code/flair/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, evaluation_metric, learning_rate, mini_batch_size, eval_mini_batch_size, max_epochs, anneal_factor, patience, anneal_against_train_loss, train_with_dev, monitor_train, embeddings_in_memory, checkpoint, save_final_model, anneal_with_restarts, test_mode, param_selection_mode, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# test best model if test data is present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mfinal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_in_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_mini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mfinal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/flair/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mfinal_test\u001b[0;34m(self, base_path, embeddings_in_memory, evaluation_metric, eval_mini_batch_size)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         test_metric, test_loss = self.evaluate(self.model, self.corpus.test, eval_mini_batch_size=eval_mini_batch_size,\n\u001b[0;32m--> 278\u001b[0;31m                                                embeddings_in_memory=embeddings_in_memory)\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'MICRO_AVG: acc {test_metric.micro_avg_accuracy()} - f1-score {test_metric.micro_avg_f_score()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/flair/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_set, eval_mini_batch_size, embeddings_in_memory, out_path)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             return ModelTrainer._evaluate_sequence_tagger(model, data_set, eval_mini_batch_size, embeddings_in_memory,\n\u001b[0;32m--> 346\u001b[0;31m                                                           out_path)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/flair/flair/trainers/trainer.py\u001b[0m in \u001b[0;36m_evaluate_sequence_tagger\u001b[0;34m(model, sentences, eval_mini_batch_size, embeddings_in_memory, out_path)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0mbatch_no\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                 \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_labels_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0meval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/flair/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward_labels_and_loss\u001b[0;34m(self, sentences, sort)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obtain_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/flair/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36m_obtain_labels\u001b[0;34m(self, feature, lengths)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_crf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mconfidences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_viterbi_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0mtag_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/flair/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36m_viterbi_decode\u001b[0;34m(self, feats)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0minit_vvars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagset_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10000.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0minit_vvars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_dictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_idx_for_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTART_TAG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m         \u001b[0mforward_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_vvars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 7. start training\n",
    "result_folder = '/home/jupyter/result_char_only/'\n",
    "trainer.train(result_folder,\n",
    "              EvaluationMetric.MICRO_F1_SCORE,\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              weight_decay = 0.1,\n",
    "              max_epochs=200,\n",
    "              checkpoint=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.visual.training_curves import Plotter\n",
    "plotter = Plotter()\n",
    "plotter.plot_training_curves(os.path.join(result_folder, 'loss.tsv'))\n",
    "# plotter.plot_weights(os.path.join(result_folder, 'weights.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-15 15:38:17,316 loading file /home/jupyter/result_word_and_char/final-model.pt\n",
      "load model okay\n",
      "dev.txt,20214,20214,0.98,B-MIS,\"الإلكترونات\"\n",
      "\n",
      "test.txt,18884,18884,0.96,I-ORG,\"مانشستر\"\n",
      "\n",
      "train.txt,37362,37362,0.97,B-LOC,\"بردى\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from predict_from_file_to_csv import *\n",
    "model_folder = result_folder \n",
    "from_model_to_solution(model_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
