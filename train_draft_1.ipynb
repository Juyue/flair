{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings\n",
    "from typing import List\n",
    "from flair.visual.training_curves import Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-13 18:20:25,555 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/ar-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpzp4frq7k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 733171328/733171328 [06:49<00:00, 1789139.10B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-13 18:27:16,060 copying /tmp/tmpzp4frq7k to cache at /home/jupyter/.flair/embeddings/ar-wiki-fasttext-300d-1M.vectors.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-13 18:27:16,827 removing temp file /tmp/tmpzp4frq7k\n",
      "2019-04-13 18:27:17,525 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/ar-wiki-fasttext-300d-1M not found in cache, downloading to /tmp/tmp875hc_rx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26704903/26704903 [00:02<00:00, 9335785.91B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-13 18:27:21,064 copying /tmp/tmp875hc_rx to cache at /home/jupyter/.flair/embeddings/ar-wiki-fasttext-300d-1M\n",
      "2019-04-13 18:27:21,093 removing temp file /tmp/tmp875hc_rx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-13 18:27:21,184 this function is deprecated, use smart_open.open instead\n"
     ]
    }
   ],
   "source": [
    "# initialize embeddings. This takes time to load.\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "    # GloVe embeddings for arabic\n",
    "    WordEmbeddings('ar'),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-13 18:31:16,855 Reading data from /home/jupyter/data_ner\n",
      "2019-04-13 18:31:16,857 Train: /home/jupyter/data_ner/train.txt\n",
      "2019-04-13 18:31:16,857 Dev: /home/jupyter/data_ner/dev.txt\n",
      "2019-04-13 18:31:16,858 Test: None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. get the corpus\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "data_folder = '/home/jupyter/data_ner/'\n",
    "corpus: TaggedCorpus = NLPTaskDataFetcher.load_column_corpus(data_folder, columns, \n",
    "  train_file='train.txt', \n",
    "  dev_file='dev.txt')\n",
    "\n",
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ner'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "\n",
    "\n",
    "# initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# have a relatively small hidden_size\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=64,\n",
    "                                        dropout = 0.2,\n",
    "                                        rnn_layers = 2,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)# initialize trainer\n",
    "# 6. Initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.training_utils import EvaluationMetric\n",
    "\n",
    "from flair.optim import AdamW\n",
    "# optimizer = optimizer(momentum=0.9, dampening=0.9)\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus, optimizer=AdamW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-13 18:47:57,765 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-13 18:47:57,766 Evaluation method: MICRO_F1_SCORE\n",
      "2019-04-13 18:47:57,782 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-13 18:47:58,003 epoch 1 - iter 0/38 - loss 12.88837433\n",
      "2019-04-13 18:47:58,872 epoch 1 - iter 3/38 - loss 28.40017533\n",
      "2019-04-13 18:47:59,777 epoch 1 - iter 6/38 - loss 23.35679831\n",
      "2019-04-13 18:48:00,761 epoch 1 - iter 9/38 - loss 21.71760406\n",
      "2019-04-13 18:48:01,506 epoch 1 - iter 12/38 - loss 19.08509687\n",
      "2019-04-13 18:48:02,890 epoch 1 - iter 15/38 - loss 20.15971559\n",
      "2019-04-13 18:48:04,171 epoch 1 - iter 18/38 - loss 19.49532649\n",
      "2019-04-13 18:48:05,290 epoch 1 - iter 21/38 - loss 18.65723636\n",
      "2019-04-13 18:48:06,219 epoch 1 - iter 24/38 - loss 18.13274155\n",
      "2019-04-13 18:48:07,199 epoch 1 - iter 27/38 - loss 17.32379975\n",
      "2019-04-13 18:48:08,029 epoch 1 - iter 30/38 - loss 16.87171238\n",
      "2019-04-13 18:48:08,893 epoch 1 - iter 33/38 - loss 16.48490757\n",
      "2019-04-13 18:48:09,924 epoch 1 - iter 36/38 - loss 16.02616586\n",
      "2019-04-13 18:48:10,073 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-13 18:48:10,074 EPOCH 1 done: loss 15.9667 - lr 0.1000 - bad epochs 0\n",
      "2019-04-13 18:48:13,200 DEV  : loss 9.92278385 - f-score 0.0246 - acc 0.0124\n",
      "2019-04-13 18:48:14,747 TEST : loss 9.43088818 - f-score 0.0204 - acc 0.0103\n",
      "2019-04-13 18:48:20,001 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-13 18:48:20,335 epoch 2 - iter 0/38 - loss 16.17512894\n",
      "2019-04-13 18:48:21,466 epoch 2 - iter 3/38 - loss 16.96130395\n",
      "2019-04-13 18:48:22,319 epoch 2 - iter 6/38 - loss 16.66326169\n",
      "2019-04-13 18:48:23,216 epoch 2 - iter 9/38 - loss 15.20661240\n",
      "2019-04-13 18:48:24,150 epoch 2 - iter 12/38 - loss 13.96294513\n",
      "2019-04-13 18:48:25,002 epoch 2 - iter 15/38 - loss 13.33328635\n",
      "2019-04-13 18:48:26,028 epoch 2 - iter 18/38 - loss 13.07550864\n",
      "2019-04-13 18:48:27,458 epoch 2 - iter 21/38 - loss 12.96016409\n",
      "2019-04-13 18:48:28,421 epoch 2 - iter 24/38 - loss 12.88686941\n",
      "2019-04-13 18:48:29,471 epoch 2 - iter 27/38 - loss 12.92893909\n",
      "2019-04-13 18:48:30,505 epoch 2 - iter 30/38 - loss 13.19069326\n",
      "2019-04-13 18:48:31,625 epoch 2 - iter 33/38 - loss 13.07607265\n",
      "2019-04-13 18:48:32,682 epoch 2 - iter 36/38 - loss 13.16600337\n",
      "2019-04-13 18:48:32,841 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-13 18:48:32,842 EPOCH 2 done: loss 13.1484 - lr 0.1000 - bad epochs 0\n",
      "2019-04-13 18:48:35,911 DEV  : loss 11.18055344 - f-score 0.2325 - acc 0.1316\n",
      "2019-04-13 18:48:37,394 TEST : loss 10.73661613 - f-score 0.1729 - acc 0.0946\n",
      "2019-04-13 18:48:48,159 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-13 18:48:48,512 epoch 3 - iter 0/38 - loss 19.83988953\n",
      "2019-04-13 18:48:49,607 epoch 3 - iter 3/38 - loss 14.33635688\n",
      "2019-04-13 18:48:50,637 epoch 3 - iter 6/38 - loss 15.15201650\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 7. start training\n",
    "result_folder = '/home/jupyter/result_64_2_l01_w01_d02_adamw/'\n",
    "trainer.train(result_folder,\n",
    "              EvaluationMetric.MICRO_F1_SCORE,\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              weight_decay = 0.1,\n",
    "              max_epochs=200,\n",
    "              checkpoint=False)\n",
    "from flair.visual.training_curves import Plotter\n",
    "plotter = Plotter()\n",
    "plotter.plot_training_curves(os.path.join(result_folder, 'loss.tsv'))\n",
    "plotter.plot_weights(os.path.join(result_folder, 'weights.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
